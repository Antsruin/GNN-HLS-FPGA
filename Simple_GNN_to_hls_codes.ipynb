{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMfjfGx0F7Qe41/x7UUl2OW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Antsruin/GNN-HLS-FPGA/blob/main/Simple_GNN_to_hls_codes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KlAk0vKMCeEG",
        "outputId": "1bf25f4d-a2f9-4bfb-affd-d5b72a486d7a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Collecting hls4ml',\n",
              " '  Downloading hls4ml-1.2.0-py3-none-any.whl.metadata (11 kB)',\n",
              " 'Requirement already satisfied: h5py in /usr/local/lib/python3.12/dist-packages (from hls4ml) (3.15.1)',\n",
              " 'Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from hls4ml) (2.0.2)',\n",
              " 'Collecting pydigitalwavetools==1.1 (from hls4ml)',\n",
              " '  Downloading pyDigitalWaveTools-1.1-py3-none-any.whl.metadata (3.1 kB)',\n",
              " 'Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from hls4ml) (6.0.3)',\n",
              " 'Collecting quantizers (from hls4ml)',\n",
              " '  Downloading quantizers-1.2.2-py3-none-any.whl.metadata (4.7 kB)',\n",
              " 'Downloading hls4ml-1.2.0-py3-none-any.whl (3.2 MB)',\n",
              " '\\x1b[?25l   \\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m0.0/3.2 MB\\x1b[0m \\x1b[31m?\\x1b[0m eta \\x1b[36m-:--:--\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m1.0/3.2 MB\\x1b[0m \\x1b[31m35.3 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m2.1/3.2 MB\\x1b[0m \\x1b[31m18.6 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m2.1/3.2 MB\\x1b[0m \\x1b[31m18.6 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m2.1/3.2 MB\\x1b[0m \\x1b[31m18.6 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━\\x1b[0m \\x1b[32m3.1/3.2 MB\\x1b[0m \\x1b[31m14.7 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m \\x1b[32m3.2/3.2 MB\\x1b[0m \\x1b[31m12.0 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m3.2/3.2 MB\\x1b[0m \\x1b[31m10.2 MB/s\\x1b[0m eta \\x1b[36m0:00:00\\x1b[0m',\n",
              " '\\x1b[?25hDownloading pyDigitalWaveTools-1.1-py3-none-any.whl (13 kB)',\n",
              " 'Downloading quantizers-1.2.2-py3-none-any.whl (15 kB)',\n",
              " 'Installing collected packages: pydigitalwavetools, quantizers, hls4ml',\n",
              " 'Successfully installed hls4ml-1.2.0 pydigitalwavetools-1.1 quantizers-1.2.2']"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "!!pip install hls4ml\n",
        "# Upload gnn_fpga_ready.h5\n",
        "# Run the conversion script"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install vivado_hls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F5-JSgpQDN7z",
        "outputId": "fc143e91-4d0b-4ac4-ee39-d75627427571"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement vivado_hls (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for vivado_hls\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import hls4ml"
      ],
      "metadata": {
        "id": "j0JDjFPoCgiH"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Custom GNN Layer using Keras\n",
        "class GNNLayer(layers.Layer):\n",
        "    \"\"\"\n",
        "    Simple Graph Neural Network Layer\n",
        "    Performs: Aggregate(neighbors) -> Dense -> Activation\n",
        "    \"\"\"\n",
        "    def __init__(self, units, activation='relu', **kwargs):\n",
        "        super(GNNLayer, self).__init__(**kwargs)\n",
        "        self.units = units\n",
        "        self.activation = keras.activations.get(activation)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        # input_shape: [(batch, nodes, features), (batch, nodes, nodes)]\n",
        "        feature_dim = input_shape[0][-1]\n",
        "        self.dense = layers.Dense(self.units, use_bias=True)\n",
        "        super(GNNLayer, self).build(input_shape)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        node_features, adj_matrix = inputs\n",
        "\n",
        "        # Aggregate: Matrix multiply adjacency with features\n",
        "        # adj_matrix: (batch, nodes, nodes)\n",
        "        # node_features: (batch, nodes, features)\n",
        "        aggregated = tf.matmul(adj_matrix, node_features)\n",
        "\n",
        "        # Transform with dense layer\n",
        "        output = self.dense(aggregated)\n",
        "\n",
        "        # Apply activation\n",
        "        output = self.activation(output)\n",
        "\n",
        "        return output\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super(GNNLayer, self).get_config()\n",
        "        config.update({\n",
        "            'units': self.units,\n",
        "            'activation': keras.activations.serialize(self.activation)\n",
        "        })\n",
        "        return config"
      ],
      "metadata": {
        "id": "l4VuAOpqCjR9"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build a simple GNN model\n",
        "def create_gnn_model(num_nodes=4, input_features=3, hidden_dim=8, output_dim=2):\n",
        "    \"\"\"\n",
        "    Create a simple 2-layer GNN model\n",
        "    \"\"\"\n",
        "    # Input layers\n",
        "    node_features_input = keras.Input(shape=(num_nodes, input_features), name='node_features')\n",
        "    adj_matrix_input = keras.Input(shape=(num_nodes, num_nodes), name='adj_matrix')\n",
        "\n",
        "    # Layer 1: GNN with ReLU\n",
        "    h1 = GNNLayer(hidden_dim, activation='relu', name='gnn_layer1')(\n",
        "        [node_features_input, adj_matrix_input]\n",
        "    )\n",
        "\n",
        "    # Layer 2: GNN without activation (for output)\n",
        "    h2 = GNNLayer(output_dim, activation='linear', name='gnn_layer2')(\n",
        "        [h1, adj_matrix_input]\n",
        "    )\n",
        "\n",
        "    model = keras.Model(\n",
        "        inputs=[node_features_input, adj_matrix_input],\n",
        "        outputs=h2,\n",
        "        name='simple_gnn'\n",
        "    )\n",
        "\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "DEvSF9ktClsF"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Alternative: Simplified version using only Dense layers (better for HLS4ML)\n",
        "def create_simplified_gnn(num_nodes=4, input_features=3, hidden_dim=8, output_dim=2):\n",
        "    \"\"\"\n",
        "    Simplified GNN using only standard Keras layers for better HLS4ML compatibility\n",
        "    Flattens the graph structure for easier synthesis\n",
        "    \"\"\"\n",
        "    # Flatten approach: concatenate all node features after aggregation\n",
        "    input_features_flat = keras.Input(shape=(num_nodes * input_features,), name='features_flat')\n",
        "\n",
        "    # Hidden layer 1\n",
        "    h1 = layers.Dense(hidden_dim * num_nodes, activation='relu', name='dense1')(input_features_flat)\n",
        "\n",
        "    # Hidden layer 2\n",
        "    h2 = layers.Dense(hidden_dim * num_nodes, activation='relu', name='dense2')(h1)\n",
        "\n",
        "    # Output layer\n",
        "    output = layers.Dense(num_nodes * output_dim, activation='linear', name='output')(h2)\n",
        "\n",
        "    model = keras.Model(inputs=input_features_flat, outputs=output, name='simplified_gnn')\n",
        "\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "Y-rJrgssCnoK"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# HLS4ML Conversion Function\n",
        "def convert_to_fpga(model, output_dir='gnn_hls4ml', board='pynq-z2'):\n",
        "    \"\"\"\n",
        "    Convert Keras model to FPGA using HLS4ML\n",
        "\n",
        "    Parameters:\n",
        "    - model: Keras model to convert\n",
        "    - output_dir: Directory for HLS4ML output\n",
        "    - board: Target FPGA board (pynq-z2, zcu102, etc.)\n",
        "    \"\"\"\n",
        "\n",
        "    # Configure HLS4ML\n",
        "    config = hls4ml.utils.config_from_keras_model(model, granularity='name')\n",
        "\n",
        "    # Set precision for weights and activations\n",
        "    config['Model']['Precision'] = 'ap_fixed<16,6>'\n",
        "    config['Model']['ReuseFactor'] = 1\n",
        "\n",
        "    # Configure each layer\n",
        "    for layer in config['LayerName'].keys():\n",
        "        config['LayerName'][layer]['Precision'] = {\n",
        "            'weight': 'ap_fixed<16,6>',\n",
        "            'bias': 'ap_fixed<16,6>',\n",
        "            'result': 'ap_fixed<16,6>'\n",
        "        }\n",
        "\n",
        "    # HLS config\n",
        "    hls_config = {\n",
        "        'Model': {\n",
        "            'Precision': 'ap_fixed<16,6>',\n",
        "            'ReuseFactor': 1,\n",
        "            'Strategy': 'Latency',  # or 'Resource'\n",
        "            'BramFactor': 10000,\n",
        "        }\n",
        "    }\n",
        "\n",
        "    print(\"Converting model to HLS...\")\n",
        "    print(f\"Output directory: {output_dir}\")\n",
        "\n",
        "    # Convert to HLS\n",
        "    hls_model = hls4ml.converters.convert_from_keras_model(\n",
        "        model,\n",
        "        hls_config=hls_config,\n",
        "        output_dir=output_dir,\n",
        "        part=f'xc7z020clg400-1' if board == 'pynq-z2' else 'xczu9eg-ffvb1156-2-e',\n",
        "        clock_period=5,\n",
        "        io_type='io_parallel'  # or 'io_stream'\n",
        "    )\n",
        "\n",
        "    # Compile the HLS model\n",
        "    hls_model.compile()\n",
        "\n",
        "    print(\"HLS model compiled successfully!\")\n",
        "\n",
        "    return hls_model"
      ],
      "metadata": {
        "id": "sa2c6M_RCqBQ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage and testing\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"=\" * 60)\n",
        "    print(\"GNN to FPGA with HLS4ML\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # Parameters\n",
        "    num_nodes = 4\n",
        "    input_features = 3\n",
        "    hidden_dim = 8\n",
        "    output_dim = 2\n",
        "\n",
        "    # Create sample data\n",
        "    # Adjacency matrix (with self-loops, normalized)\n",
        "    adj = np.array([\n",
        "        [1, 1, 0, 0],\n",
        "        [1, 1, 1, 0],\n",
        "        [0, 1, 1, 1],\n",
        "        [0, 0, 1, 1]\n",
        "    ], dtype=np.float32)\n",
        "\n",
        "    # Normalize adjacency matrix\n",
        "    degree = np.sum(adj, axis=1, keepdims=True)\n",
        "    adj_normalized = adj / degree\n",
        "    adj_normalized = adj_normalized[np.newaxis, ...]  # Add batch dimension\n",
        "\n",
        "    # Node features\n",
        "    features = np.array([\n",
        "        [1.0, 0.5, 0.2],\n",
        "        [0.8, 0.3, 0.9],\n",
        "        [0.2, 0.7, 0.4],\n",
        "        [0.6, 0.1, 0.8]\n",
        "    ], dtype=np.float32)\n",
        "    features = features[np.newaxis, ...]  # Add batch dimension\n",
        "\n",
        "    print(\"\\n1. Creating Simplified GNN Model (Best for HLS4ML)...\")\n",
        "    # Use simplified version - better compatibility\n",
        "    features_flat = features.reshape(1, -1)\n",
        "    model = create_simplified_gnn(num_nodes, input_features, hidden_dim, output_dim)\n",
        "    model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "    print(\"\\nModel Summary:\")\n",
        "    model.summary()\n",
        "\n",
        "    # Test the model\n",
        "    print(\"\\n2. Testing Model...\")\n",
        "    output = model.predict(features_flat, verbose=0)\n",
        "    print(f\"Input shape: {features_flat.shape}\")\n",
        "    print(f\"Output shape: {output.shape}\")\n",
        "    print(f\"Sample output:\\n{output.reshape(num_nodes, output_dim)}\")\n",
        "\n",
        "    # Convert to FPGA\n",
        "    print(\"\\n3. Converting to FPGA with HLS4ML...\")\n",
        "    print(\"Note: This requires hls4ml to be installed: pip install hls4ml\")\n",
        "    print(\"      And Xilinx Vivado HLS to be available on the system\")\n",
        "\n",
        "\n",
        "    hls_model = convert_to_fpga(\n",
        "        model,\n",
        "        output_dir='gnn_fpga_output',\n",
        "        board='pynq-z2'\n",
        "    )\n",
        "\n",
        "    # Test HLS model\n",
        "    print(\"\\n4. Testing HLS Model...\")\n",
        "    hls_output = hls_model.predict(features_flat)\n",
        "    print(f\"HLS Output shape: {hls_output.shape}\")\n",
        "    print(f\"HLS Output:\\n{hls_output.reshape(num_nodes, output_dim)}\")\n",
        "\n",
        "    # Compare outputs\n",
        "    print(\"\\n5. Comparing Keras vs HLS outputs...\")\n",
        "    diff = np.abs(output - hls_output)\n",
        "    print(f\"Maximum difference: {np.max(diff):.6f}\")\n",
        "    print(f\"Mean difference: {np.mean(diff):.6f}\")\n",
        "\n",
        "\n",
        "    # Save the Keras model for later use\n",
        "    print(\"\\n7. Saving Keras model...\")\n",
        "    model.save('gnn_model.h5')\n",
        "    print(\"Model saved as 'gnn_model.h5'\")\n",
        "    print(\"\\nYou can load it later with: model = keras.models.load_model('gnn_model.h5')\")\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"Process Complete!\")\n",
        "    print(\"=\" * 60)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "_4NAXnBYCsaj",
        "outputId": "b0dd28d8-c1b0-45a3-bcb7-48ae7349a90a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "GNN to FPGA with HLS4ML\n",
            "============================================================\n",
            "\n",
            "1. Creating Simplified GNN Model (Best for HLS4ML)...\n",
            "\n",
            "Model Summary:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"simplified_gnn\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"simplified_gnn\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ features_flat (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense1 (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │           \u001b[38;5;34m416\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense2 (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m1,056\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ output (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │           \u001b[38;5;34m264\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ features_flat (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">416</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,056</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">264</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,736\u001b[0m (6.78 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,736</span> (6.78 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,736\u001b[0m (6.78 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,736</span> (6.78 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "2. Testing Model...\n",
            "Input shape: (1, 12)\n",
            "Output shape: (1, 8)\n",
            "Sample output:\n",
            "[[ 0.1494176   0.03711023]\n",
            " [ 0.0198466   0.36051148]\n",
            " [ 0.09396695  0.43737856]\n",
            " [-0.36304754  0.03990293]]\n",
            "\n",
            "3. Converting to FPGA with HLS4ML...\n",
            "Note: This requires hls4ml to be installed: pip install hls4ml\n",
            "      And Xilinx Vivado HLS to be available on the system\n",
            "Converting model to HLS...\n",
            "Output directory: gnn_fpga_output\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HLS model compiled successfully!\n",
            "\n",
            "4. Testing HLS Model...\n",
            "HLS Output shape: (8,)\n",
            "HLS Output:\n",
            "[[ 0.12988281  0.02929688]\n",
            " [ 0.02246094  0.3251953 ]\n",
            " [ 0.08496094  0.41210938]\n",
            " [-0.35839844  0.02734375]]\n",
            "\n",
            "5. Comparing Keras vs HLS outputs...\n",
            "Maximum difference: 0.035316\n",
            "Mean difference: 0.014595\n",
            "\n",
            "7. Saving Keras model...\n",
            "Model saved as 'gnn_model.h5'\n",
            "\n",
            "You can load it later with: model = keras.models.load_model('gnn_model.h5')\n",
            "\n",
            "============================================================\n",
            "Process Complete!\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xCvx7oo2CvaR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}